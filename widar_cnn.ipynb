{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNJi5nG94rccD01hB5iKkBa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR3KhliWK0EH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4de6a41-2e19-4426-f075-0389ad519196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "\n",
        "# Directory where data is stored\n",
        "data_dir = 'DFS/big-single-data'\n",
        "\n",
        "# Directory to save results\n",
        "model_dir = 'final/single'\n",
        "\n",
        "# Ensure the save directory exists\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Load the saved data\n",
        "data_file = os.path.join(data_dir, 'data_receiver_1.npy')\n",
        "label_file = os.path.join(data_dir, 'label_receiver_1.npy')\n",
        "data = np.load(data_file)\n",
        "labels = np.load(label_file)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Perform One-hot encoding on the labels\n",
        "N_MOTION = len(np.unique(labels))\n",
        "labels_train = to_categorical(labels_train - 1, N_MOTION)\n",
        "labels_test = to_categorical(labels_test - 1, N_MOTION)\n",
        "\n",
        "# Define the input shape for the model\n",
        "input_shape = (data.shape[1], data.shape[2], 1)\n",
        "\n",
        "# Assemble the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(N_MOTION, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Set up ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "# Train the model and display accuracy for each epoch\n",
        "history = model.fit(data_train, labels_train, batch_size=32, epochs=90, validation_split=0.2, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# Print training and validation accuracy for each epoch\n",
        "for epoch, acc, val_acc in zip(range(len(history.history['accuracy'])), history.history['accuracy'], history.history['val_accuracy']):\n",
        "    print(f\"Epoch {epoch+1}, Training Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(data_test, labels_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Predict and generate confusion matrix\n",
        "labels_test_pred = model.predict(data_test)\n",
        "labels_test_pred = np.argmax(labels_test_pred, axis=-1) + 1\n",
        "labels_test_true = np.argmax(labels_test, axis=-1) + 1\n",
        "\n",
        "cm = confusion_matrix(labels_test_true, labels_test_pred)\n",
        "print(cm)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = np.around(cm, decimals=2)\n",
        "print(cm)\n",
        "\n",
        "# Save training history\n",
        "with open(os.path.join(model_dir, 'single_view_history.pkl'), 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "# Save predicted and true labels\n",
        "np.save(os.path.join(model_dir, 'single_view_labels_test_true.npy'), labels_test_true)\n",
        "np.save(os.path.join(model_dir, 'single_view_labels_test_pred.npy'), labels_test_pred)\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Single View Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(model_dir, 'single_view_accuracy.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plot training and validation loss curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Single View Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(model_dir, 'single_view_loss.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "plt.title('Single View Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.savefig(os.path.join(model_dir, 'single_view_confusion_matrix.png'))\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tBhT-Pab1Av3",
        "outputId": "214ef043-02b0-401b-92a7-2ffff3604041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2970\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1485\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2803680\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ feature_layer (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │     \u001b[38;5;34m179,435,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m390\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2970</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1485</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2803680</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ feature_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">179,435,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,436,294\u001b[0m (684.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,436,294</span> (684.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,436,294\u001b[0m (684.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,436,294</span> (684.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 317ms/step - accuracy: 0.2965 - loss: 5.1263 - val_accuracy: 0.3556 - val_loss: 1.4691 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.3499 - loss: 1.5171 - val_accuracy: 0.4025 - val_loss: 1.3828 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.3485 - loss: 1.4653 - val_accuracy: 0.4222 - val_loss: 1.2909 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.3865 - loss: 1.4020 - val_accuracy: 0.4370 - val_loss: 1.3855 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.3977 - loss: 1.3682 - val_accuracy: 0.4691 - val_loss: 1.2581 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.4448 - loss: 1.2570 - val_accuracy: 0.4642 - val_loss: 1.2552 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.4368 - loss: 1.2817 - val_accuracy: 0.4963 - val_loss: 1.2077 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.4722 - loss: 1.2107 - val_accuracy: 0.4988 - val_loss: 1.1848 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.4684 - loss: 1.1820 - val_accuracy: 0.5062 - val_loss: 1.1890 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.4984 - loss: 1.1501 - val_accuracy: 0.5259 - val_loss: 1.1548 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.5101 - loss: 1.0998 - val_accuracy: 0.5358 - val_loss: 1.1555 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5197 - loss: 1.1183 - val_accuracy: 0.5457 - val_loss: 1.1335 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5043 - loss: 1.0773 - val_accuracy: 0.5309 - val_loss: 1.1776 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5431 - loss: 1.0457 - val_accuracy: 0.5210 - val_loss: 1.1200 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5261 - loss: 1.0814 - val_accuracy: 0.5407 - val_loss: 1.1206 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5602 - loss: 1.0417 - val_accuracy: 0.5679 - val_loss: 1.1002 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5704 - loss: 1.0116 - val_accuracy: 0.5481 - val_loss: 1.1159 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5640 - loss: 0.9832 - val_accuracy: 0.5605 - val_loss: 1.0898 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5225 - loss: 1.0281 - val_accuracy: 0.5630 - val_loss: 1.1101 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.5626 - loss: 0.9390 - val_accuracy: 0.5309 - val_loss: 1.1469 - learning_rate: 0.0010\n",
            "Epoch 1, Training Accuracy: 0.3082, Validation Accuracy: 0.3556\n",
            "Epoch 2, Training Accuracy: 0.3657, Validation Accuracy: 0.4025\n",
            "Epoch 3, Training Accuracy: 0.3762, Validation Accuracy: 0.4222\n",
            "Epoch 4, Training Accuracy: 0.3947, Validation Accuracy: 0.4370\n",
            "Epoch 5, Training Accuracy: 0.4052, Validation Accuracy: 0.4691\n",
            "Epoch 6, Training Accuracy: 0.4497, Validation Accuracy: 0.4642\n",
            "Epoch 7, Training Accuracy: 0.4546, Validation Accuracy: 0.4963\n",
            "Epoch 8, Training Accuracy: 0.4670, Validation Accuracy: 0.4988\n",
            "Epoch 9, Training Accuracy: 0.4855, Validation Accuracy: 0.5062\n",
            "Epoch 10, Training Accuracy: 0.4910, Validation Accuracy: 0.5259\n",
            "Epoch 11, Training Accuracy: 0.4947, Validation Accuracy: 0.5358\n",
            "Epoch 12, Training Accuracy: 0.4960, Validation Accuracy: 0.5457\n",
            "Epoch 13, Training Accuracy: 0.5127, Validation Accuracy: 0.5309\n",
            "Epoch 14, Training Accuracy: 0.5454, Validation Accuracy: 0.5210\n",
            "Epoch 15, Training Accuracy: 0.5312, Validation Accuracy: 0.5407\n",
            "Epoch 16, Training Accuracy: 0.5540, Validation Accuracy: 0.5679\n",
            "Epoch 17, Training Accuracy: 0.5608, Validation Accuracy: 0.5481\n",
            "Epoch 18, Training Accuracy: 0.5497, Validation Accuracy: 0.5605\n",
            "Epoch 19, Training Accuracy: 0.5337, Validation Accuracy: 0.5630\n",
            "Epoch 20, Training Accuracy: 0.5670, Validation Accuracy: 0.5309\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.5664 - loss: 1.0918\n",
            "Test accuracy: 0.551111102104187\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The layer sequential has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5ea9a1a43db9>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# 提取特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The layer sequential has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "\n",
        "# Define data directory\n",
        "model_dir = 'DFS/big-multi-data'\n",
        "save_dir = 'final/multi'\n",
        "\n",
        "# Create save directory (if it doesn't exist)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Load saved data\n",
        "data_file = os.path.join(model_dir, 'data.npy')\n",
        "label_file = os.path.join(model_dir, 'label.npy')\n",
        "data = np.load(data_file)\n",
        "labels = np.load(label_file)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Perform One-hot encoding on the labels\n",
        "N_MOTION = len(np.unique(labels))\n",
        "labels_train = to_categorical(labels_train - 1, N_MOTION)\n",
        "labels_test = to_categorical(labels_test - 1, N_MOTION)\n",
        "\n",
        "# Model input shape\n",
        "input_shape = (data.shape[1], data.shape[2], 1)\n",
        "\n",
        "# Define subnetwork for feature extraction\n",
        "def create_subnetwork(input_shape):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    return input_layer, x\n",
        "\n",
        "# Build three subnetworks to process data from three receivers\n",
        "inputs = []\n",
        "features = []\n",
        "for i in range(3):\n",
        "    input_layer, feature = create_subnetwork(input_shape)\n",
        "    inputs.append(input_layer)\n",
        "    features.append(feature)\n",
        "\n",
        "# Concatenate the outputs of the subnetworks\n",
        "merged_features = Concatenate()(features)\n",
        "x = Dense(128, activation='relu')(merged_features)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(N_MOTION, activation='softmax')(x)\n",
        "\n",
        "# Build and compile the model\n",
        "optimizer = Adam()  # Use default learning rate 0.001\n",
        "model = Model(inputs=inputs, outputs=output_layer)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Prepare training data\n",
        "train_data = [data_train[:, :, :, i:i+1] for i in range(3)]\n",
        "test_data = [data_test[:, :, :, i:i+1] for i in range(3)]\n",
        "\n",
        "# Set up ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, labels_train, batch_size=32, epochs=90, validation_split=0.2, callbacks=[reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_data, labels_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Extract features\n",
        "feature_extractor = Model(inputs=inputs, outputs=features)\n",
        "train_features = feature_extractor.predict(train_data)\n",
        "test_features = feature_extractor.predict(test_data)\n",
        "\n",
        "# Save feature data to final/multi directory\n",
        "for i in range(3):\n",
        "    np.save(os.path.join(save_dir, f'train_features_receiver_{i+1}.npy'), train_features[i])\n",
        "    np.save(os.path.join(save_dir, f'test_features_receiver_{i+1}.npy'), test_features[i])\n",
        "\n",
        "# Predict and generate confusion matrix\n",
        "labels_test_pred = model.predict(test_data)\n",
        "labels_test_pred = np.argmax(labels_test_pred, axis=-1) + 1\n",
        "labels_test_true = np.argmax(labels_test, axis=-1) + 1\n",
        "\n",
        "cm = confusion_matrix(labels_test_true, labels_test_pred)\n",
        "print(cm)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = np.around(cm, decimals=2)\n",
        "print(cm)\n",
        "\n",
        "# Save training history\n",
        "with open(os.path.join(model_dir, 'multi_view_history.pkl'), 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "# Save predicted and true labels\n",
        "np.save(os.path.join(model_dir, 'multi_view_labels_test_true.npy'), labels_test_true)\n",
        "np.save(os.path.join(model_dir, 'multi_view_labels_test_pred.npy'), labels_test_pred)\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Multi View Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(model_dir, 'multi_view_accuracy.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plot training and validation loss curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Multi View Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(model_dir, 'multi_view_loss.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "plt.title('Multi View Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.savefig(os.path.join(model_dir, 'multi_view_confusion_matrix.png'))\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "424zJUn-y0ju",
        "outputId": "21f33b3b-0bd4-4afa-cedd-8eddba7b70c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2972\u001b[0m, \u001b[38;5;34m121\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2972\u001b[0m, \u001b[38;5;34m121\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2972\u001b[0m, \u001b[38;5;34m121\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2970\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │            \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2970\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │            \u001b[38;5;34m320\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2970\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │            \u001b[38;5;34m320\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1485\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1485\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1485\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2803680\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2803680\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2803680\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m179,435,584\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m179,435,584\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m179,435,584\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m24,704\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m774\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2972</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">121</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2972</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">121</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2972</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">121</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2970</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2970</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2970</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1485</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1485</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1485</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2803680</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2803680</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2803680</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,435,584</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,435,584</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,435,584</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m538,333,190\u001b[0m (2.01 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,333,190</span> (2.01 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m538,333,190\u001b[0m (2.01 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,333,190</span> (2.01 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 286ms/step - accuracy: 0.2508 - loss: 6.9052 - val_accuracy: 0.4173 - val_loss: 1.5105 - learning_rate: 0.0010\n",
            "Epoch 2/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.3180 - loss: 1.5770 - val_accuracy: 0.4667 - val_loss: 1.3416 - learning_rate: 0.0010\n",
            "Epoch 3/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.4114 - loss: 1.4200 - val_accuracy: 0.5111 - val_loss: 1.2864 - learning_rate: 0.0010\n",
            "Epoch 4/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.4298 - loss: 1.3509 - val_accuracy: 0.5309 - val_loss: 1.2413 - learning_rate: 0.0010\n",
            "Epoch 5/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.4522 - loss: 1.3173 - val_accuracy: 0.5309 - val_loss: 1.2088 - learning_rate: 0.0010\n",
            "Epoch 6/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.4618 - loss: 1.2788 - val_accuracy: 0.5556 - val_loss: 1.1586 - learning_rate: 0.0010\n",
            "Epoch 7/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.5396 - loss: 1.1659 - val_accuracy: 0.5556 - val_loss: 1.1044 - learning_rate: 0.0010\n",
            "Epoch 8/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.5593 - loss: 1.0597 - val_accuracy: 0.5605 - val_loss: 1.0912 - learning_rate: 0.0010\n",
            "Epoch 9/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.5899 - loss: 1.0001 - val_accuracy: 0.5753 - val_loss: 1.1164 - learning_rate: 0.0010\n",
            "Epoch 10/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.6255 - loss: 0.9375 - val_accuracy: 0.5753 - val_loss: 1.0591 - learning_rate: 0.0010\n",
            "Epoch 11/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.6464 - loss: 0.9064 - val_accuracy: 0.5704 - val_loss: 1.0319 - learning_rate: 0.0010\n",
            "Epoch 12/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.6342 - loss: 0.8524 - val_accuracy: 0.5852 - val_loss: 1.0451 - learning_rate: 0.0010\n",
            "Epoch 13/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.6856 - loss: 0.8105 - val_accuracy: 0.5951 - val_loss: 1.0259 - learning_rate: 0.0010\n",
            "Epoch 14/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7080 - loss: 0.7812 - val_accuracy: 0.5556 - val_loss: 1.0771 - learning_rate: 0.0010\n",
            "Epoch 15/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.6990 - loss: 0.7533 - val_accuracy: 0.5827 - val_loss: 1.0682 - learning_rate: 0.0010\n",
            "Epoch 16/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7164 - loss: 0.7290 - val_accuracy: 0.5852 - val_loss: 1.1020 - learning_rate: 0.0010\n",
            "Epoch 17/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.7478 - loss: 0.6477 - val_accuracy: 0.5827 - val_loss: 1.1133 - learning_rate: 0.0010\n",
            "Epoch 18/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7466 - loss: 0.6543 \n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.7467 - loss: 0.6541 - val_accuracy: 0.5704 - val_loss: 1.1093 - learning_rate: 0.0010\n",
            "Epoch 19/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.7818 - loss: 0.5665 - val_accuracy: 0.5901 - val_loss: 1.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 20/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8132 - loss: 0.4719 - val_accuracy: 0.5778 - val_loss: 1.1089 - learning_rate: 5.0000e-04\n",
            "Epoch 21/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7704 - loss: 0.5803 - val_accuracy: 0.5679 - val_loss: 1.1565 - learning_rate: 5.0000e-04\n",
            "Epoch 22/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7892 - loss: 0.5651 - val_accuracy: 0.5753 - val_loss: 1.1458 - learning_rate: 5.0000e-04\n",
            "Epoch 23/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8092 - loss: 0.5029 \n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8094 - loss: 0.5026 - val_accuracy: 0.5802 - val_loss: 1.1752 - learning_rate: 5.0000e-04\n",
            "Epoch 24/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7904 - loss: 0.5637 - val_accuracy: 0.6025 - val_loss: 1.1471 - learning_rate: 2.5000e-04\n",
            "Epoch 25/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8441 - loss: 0.4210 - val_accuracy: 0.5877 - val_loss: 1.1698 - learning_rate: 2.5000e-04\n",
            "Epoch 26/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8028 - loss: 0.4781 - val_accuracy: 0.5926 - val_loss: 1.1551 - learning_rate: 2.5000e-04\n",
            "Epoch 27/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8442 - loss: 0.4424 - val_accuracy: 0.5975 - val_loss: 1.1952 - learning_rate: 2.5000e-04\n",
            "Epoch 28/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8486 - loss: 0.3956\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8485 - loss: 0.3957 - val_accuracy: 0.5852 - val_loss: 1.2236 - learning_rate: 2.5000e-04\n",
            "Epoch 29/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8306 - loss: 0.4296 - val_accuracy: 0.5951 - val_loss: 1.2020 - learning_rate: 1.2500e-04\n",
            "Epoch 30/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8514 - loss: 0.3824 - val_accuracy: 0.6049 - val_loss: 1.2162 - learning_rate: 1.2500e-04\n",
            "Epoch 31/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8414 - loss: 0.4315 - val_accuracy: 0.5975 - val_loss: 1.2300 - learning_rate: 1.2500e-04\n",
            "Epoch 32/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8566 - loss: 0.3702 - val_accuracy: 0.5951 - val_loss: 1.2441 - learning_rate: 1.2500e-04\n",
            "Epoch 33/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8677 - loss: 0.3767\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8675 - loss: 0.3769 - val_accuracy: 0.6074 - val_loss: 1.2420 - learning_rate: 1.2500e-04\n",
            "Epoch 34/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8554 - loss: 0.4089 - val_accuracy: 0.5951 - val_loss: 1.2329 - learning_rate: 6.2500e-05\n",
            "Epoch 35/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8666 - loss: 0.3661 - val_accuracy: 0.5926 - val_loss: 1.2374 - learning_rate: 6.2500e-05\n",
            "Epoch 36/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8616 - loss: 0.3639 - val_accuracy: 0.6099 - val_loss: 1.2383 - learning_rate: 6.2500e-05\n",
            "Epoch 37/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8631 - loss: 0.3792 - val_accuracy: 0.5926 - val_loss: 1.2615 - learning_rate: 6.2500e-05\n",
            "Epoch 38/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8611 - loss: 0.3696\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8610 - loss: 0.3697 - val_accuracy: 0.6049 - val_loss: 1.2457 - learning_rate: 6.2500e-05\n",
            "Epoch 39/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8730 - loss: 0.3617 - val_accuracy: 0.5951 - val_loss: 1.2556 - learning_rate: 3.1250e-05\n",
            "Epoch 40/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8869 - loss: 0.3289 - val_accuracy: 0.6123 - val_loss: 1.2642 - learning_rate: 3.1250e-05\n",
            "Epoch 41/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8528 - loss: 0.3950 - val_accuracy: 0.6099 - val_loss: 1.2688 - learning_rate: 3.1250e-05\n",
            "Epoch 42/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8619 - loss: 0.3692 - val_accuracy: 0.6025 - val_loss: 1.2621 - learning_rate: 3.1250e-05\n",
            "Epoch 43/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8845 - loss: 0.3577 \n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8844 - loss: 0.3576 - val_accuracy: 0.6074 - val_loss: 1.2781 - learning_rate: 3.1250e-05\n",
            "Epoch 44/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8440 - loss: 0.4061 - val_accuracy: 0.6000 - val_loss: 1.2773 - learning_rate: 1.5625e-05\n",
            "Epoch 45/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8651 - loss: 0.3768 - val_accuracy: 0.5975 - val_loss: 1.2773 - learning_rate: 1.5625e-05\n",
            "Epoch 46/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8657 - loss: 0.3656 - val_accuracy: 0.6025 - val_loss: 1.2776 - learning_rate: 1.5625e-05\n",
            "Epoch 47/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8665 - loss: 0.3825 - val_accuracy: 0.6049 - val_loss: 1.2744 - learning_rate: 1.5625e-05\n",
            "Epoch 48/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8656 - loss: 0.3518\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8657 - loss: 0.3518 - val_accuracy: 0.6148 - val_loss: 1.2818 - learning_rate: 1.5625e-05\n",
            "Epoch 49/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8560 - loss: 0.3773 - val_accuracy: 0.6074 - val_loss: 1.2827 - learning_rate: 1.0000e-05\n",
            "Epoch 50/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8876 - loss: 0.3493 - val_accuracy: 0.6049 - val_loss: 1.2827 - learning_rate: 1.0000e-05\n",
            "Epoch 51/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8787 - loss: 0.3398 - val_accuracy: 0.6074 - val_loss: 1.2790 - learning_rate: 1.0000e-05\n",
            "Epoch 52/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8501 - loss: 0.3945 - val_accuracy: 0.6099 - val_loss: 1.2839 - learning_rate: 1.0000e-05\n",
            "Epoch 53/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8546 - loss: 0.4024 - val_accuracy: 0.6074 - val_loss: 1.2852 - learning_rate: 1.0000e-05\n",
            "Epoch 54/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8750 - loss: 0.3472 - val_accuracy: 0.6099 - val_loss: 1.2922 - learning_rate: 1.0000e-05\n",
            "Epoch 55/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8654 - loss: 0.3606 - val_accuracy: 0.6074 - val_loss: 1.2983 - learning_rate: 1.0000e-05\n",
            "Epoch 56/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8707 - loss: 0.3567 - val_accuracy: 0.6099 - val_loss: 1.2989 - learning_rate: 1.0000e-05\n",
            "Epoch 57/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8836 - loss: 0.3289 - val_accuracy: 0.6049 - val_loss: 1.2989 - learning_rate: 1.0000e-05\n",
            "Epoch 58/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8686 - loss: 0.3677 - val_accuracy: 0.6049 - val_loss: 1.2960 - learning_rate: 1.0000e-05\n",
            "Epoch 59/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8665 - loss: 0.3626 - val_accuracy: 0.6049 - val_loss: 1.2989 - learning_rate: 1.0000e-05\n",
            "Epoch 60/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8694 - loss: 0.3466 - val_accuracy: 0.6049 - val_loss: 1.2981 - learning_rate: 1.0000e-05\n",
            "Epoch 61/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8650 - loss: 0.3521 - val_accuracy: 0.6025 - val_loss: 1.2936 - learning_rate: 1.0000e-05\n",
            "Epoch 62/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8625 - loss: 0.3594 - val_accuracy: 0.6049 - val_loss: 1.2897 - learning_rate: 1.0000e-05\n",
            "Epoch 63/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8735 - loss: 0.3567 - val_accuracy: 0.6074 - val_loss: 1.2905 - learning_rate: 1.0000e-05\n",
            "Epoch 64/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8715 - loss: 0.3535 - val_accuracy: 0.6074 - val_loss: 1.2982 - learning_rate: 1.0000e-05\n",
            "Epoch 65/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8628 - loss: 0.3623 - val_accuracy: 0.6074 - val_loss: 1.2953 - learning_rate: 1.0000e-05\n",
            "Epoch 66/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8740 - loss: 0.3559 - val_accuracy: 0.6074 - val_loss: 1.2988 - learning_rate: 1.0000e-05\n",
            "Epoch 67/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8853 - loss: 0.3383 - val_accuracy: 0.6074 - val_loss: 1.3064 - learning_rate: 1.0000e-05\n",
            "Epoch 68/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8639 - loss: 0.3594 - val_accuracy: 0.6074 - val_loss: 1.3105 - learning_rate: 1.0000e-05\n",
            "Epoch 69/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8678 - loss: 0.3724 - val_accuracy: 0.6099 - val_loss: 1.3097 - learning_rate: 1.0000e-05\n",
            "Epoch 70/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8634 - loss: 0.3644 - val_accuracy: 0.6099 - val_loss: 1.3106 - learning_rate: 1.0000e-05\n",
            "Epoch 71/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8746 - loss: 0.3587 - val_accuracy: 0.6123 - val_loss: 1.3049 - learning_rate: 1.0000e-05\n",
            "Epoch 72/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8822 - loss: 0.3249 - val_accuracy: 0.6099 - val_loss: 1.3068 - learning_rate: 1.0000e-05\n",
            "Epoch 73/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8654 - loss: 0.3659 - val_accuracy: 0.6099 - val_loss: 1.3088 - learning_rate: 1.0000e-05\n",
            "Epoch 74/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8905 - loss: 0.3115 - val_accuracy: 0.6049 - val_loss: 1.3093 - learning_rate: 1.0000e-05\n",
            "Epoch 75/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8660 - loss: 0.3645 - val_accuracy: 0.6099 - val_loss: 1.3124 - learning_rate: 1.0000e-05\n",
            "Epoch 76/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8548 - loss: 0.3635 - val_accuracy: 0.6074 - val_loss: 1.3211 - learning_rate: 1.0000e-05\n",
            "Epoch 77/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8782 - loss: 0.3373 - val_accuracy: 0.6099 - val_loss: 1.3249 - learning_rate: 1.0000e-05\n",
            "Epoch 78/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8859 - loss: 0.3430 - val_accuracy: 0.6025 - val_loss: 1.3253 - learning_rate: 1.0000e-05\n",
            "Epoch 79/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8765 - loss: 0.3368 - val_accuracy: 0.6074 - val_loss: 1.3253 - learning_rate: 1.0000e-05\n",
            "Epoch 80/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8619 - loss: 0.3594 - val_accuracy: 0.6049 - val_loss: 1.3262 - learning_rate: 1.0000e-05\n",
            "Epoch 81/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8903 - loss: 0.3195 - val_accuracy: 0.6074 - val_loss: 1.3287 - learning_rate: 1.0000e-05\n",
            "Epoch 82/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8661 - loss: 0.3576 - val_accuracy: 0.6025 - val_loss: 1.3311 - learning_rate: 1.0000e-05\n",
            "Epoch 83/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8665 - loss: 0.3530 - val_accuracy: 0.6025 - val_loss: 1.3345 - learning_rate: 1.0000e-05\n",
            "Epoch 84/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8598 - loss: 0.3678 - val_accuracy: 0.6025 - val_loss: 1.3363 - learning_rate: 1.0000e-05\n",
            "Epoch 85/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8779 - loss: 0.3399 - val_accuracy: 0.6049 - val_loss: 1.3305 - learning_rate: 1.0000e-05\n",
            "Epoch 86/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8746 - loss: 0.3574 - val_accuracy: 0.6049 - val_loss: 1.3301 - learning_rate: 1.0000e-05\n",
            "Epoch 87/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8721 - loss: 0.3317 - val_accuracy: 0.6000 - val_loss: 1.3359 - learning_rate: 1.0000e-05\n",
            "Epoch 88/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8724 - loss: 0.3302 - val_accuracy: 0.6000 - val_loss: 1.3359 - learning_rate: 1.0000e-05\n",
            "Epoch 89/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8643 - loss: 0.3763 - val_accuracy: 0.6049 - val_loss: 1.3374 - learning_rate: 1.0000e-05\n",
            "Epoch 90/90\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8622 - loss: 0.3627 - val_accuracy: 0.6025 - val_loss: 1.3473 - learning_rate: 1.0000e-05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5944 - loss: 1.2680\n",
            "Test accuracy: 0.6044444441795349\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "[[19  7  3 10  0  0]\n",
            " [ 3 26  4  3  0  0]\n",
            " [ 0  2 35  0  0  0]\n",
            " [12  5  1 14  3  0]\n",
            " [ 2  3  0  7 22 10]\n",
            " [ 0  3  0  1 10 20]]\n",
            "[[0.49 0.18 0.08 0.26 0.   0.  ]\n",
            " [0.08 0.72 0.11 0.08 0.   0.  ]\n",
            " [0.   0.05 0.95 0.   0.   0.  ]\n",
            " [0.34 0.14 0.03 0.4  0.09 0.  ]\n",
            " [0.05 0.07 0.   0.16 0.5  0.23]\n",
            " [0.   0.09 0.   0.03 0.29 0.59]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import argparse\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "\n",
        "class MultiViewDFSIB(nn.Module):\n",
        "    def __init__(self, input_dim, time_dim, hidden_dim, output_dim, args):\n",
        "        super(MultiViewDFSIB, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "\n",
        "        # Define feature extraction networks for each view\n",
        "        self.view1_feature_extraction = nn.Sequential(\n",
        "            nn.Linear(time_dim * input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.view2_feature_extraction = nn.Sequential(\n",
        "            nn.Linear(time_dim * input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.view3_feature_extraction = nn.Sequential(\n",
        "            nn.Linear(time_dim * input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Define IB (Information Bottleneck) layers for each view\n",
        "        self.view1_ib_mu = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.view2_ib_mu = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.view3_ib_mu = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.view1_ib_sigma = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view2_ib_sigma = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view3_ib_sigma = nn.Sequential(\n",
        "            nn.Linear(256, 32),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Define encoders for each view\n",
        "        self.view1_encoder1 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim1']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view1_encoder2 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim2']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view2_encoder1 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim1']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view2_encoder2 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim2']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view3_encoder1 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim1']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.view3_encoder2 = nn.Sequential(\n",
        "            nn.Linear(32, args['dim2']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Define decoders for each view\n",
        "        self.view_specific_decoder1 = nn.Sequential(\n",
        "            nn.Linear(args['dim1'] + args['dim2'], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "        self.view_specific_decoder2 = nn.Sequential(\n",
        "            nn.Linear(args['dim1'] + args['dim2'], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "        self.view_specific_decoder3 = nn.Sequential(\n",
        "            nn.Linear(args['dim1'] + args['dim2'], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "        # Define final decoders for combined features\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.Linear(3 * args['dim1'], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.Linear(3 * (args['dim1'] + args['dim2']), 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, sigma):\n",
        "        std = torch.exp(0.5 * sigma)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x, args):\n",
        "        feature1, feature2, feature3, KL_loss = self.IB_feature_extraction(x)\n",
        "\n",
        "        encoded_view1_1 = self.view1_encoder1(feature1)\n",
        "        encoded_view2_1 = self.view2_encoder1(feature2)\n",
        "        encoded_view3_1 = self.view3_encoder1(feature3)\n",
        "\n",
        "        encoded_view1_2 = self.view1_encoder2(feature1)\n",
        "        encoded_view2_2 = self.view2_encoder2(feature2)\n",
        "        encoded_view3_2 = self.view3_encoder2(feature3)\n",
        "\n",
        "        quantized_view1_1 = (torch.round(encoded_view1_1) - encoded_view1_1).detach() + encoded_view1_1 - 0.5\n",
        "        quantized_view2_1 = (torch.round(encoded_view2_1) - encoded_view2_1).detach() + encoded_view2_1 - 0.5\n",
        "        quantized_view3_1 = (torch.round(encoded_view3_1) - encoded_view3_1).detach() + encoded_view3_1 - 0.5\n",
        "\n",
        "        quantized_view1_2 = (torch.round(encoded_view1_2) - encoded_view1_2).detach() + encoded_view1_2 - 0.5\n",
        "        quantized_view2_2 = (torch.round(encoded_view2_2) - encoded_view2_2).detach() + encoded_view2_2 - 0.5\n",
        "        quantized_view3_2 = (torch.round(encoded_view3_2) - encoded_view3_2).detach() + encoded_view3_2 - 0.5\n",
        "\n",
        "        # Save encoded features to the specified directory\n",
        "        self.save_encoded_features(quantized_view1_1, quantized_view2_1, quantized_view3_1,\n",
        "                                   quantized_view1_2, quantized_view2_2, quantized_view3_2)\n",
        "\n",
        "        view_specific_feature1 = torch.cat((quantized_view1_1, quantized_view1_2), dim=1)\n",
        "        view_specific_feature2 = torch.cat((quantized_view2_1, quantized_view2_2), dim=1)\n",
        "        view_specific_feature3 = torch.cat((quantized_view3_1, quantized_view3_2), dim=1)\n",
        "\n",
        "        received_feature_T1 = torch.cat((quantized_view1_1, quantized_view2_1, quantized_view3_1), dim=1)\n",
        "        received_feature_T2 = torch.cat((view_specific_feature1, view_specific_feature2, view_specific_feature3), dim=1)\n",
        "\n",
        "        view_specific_output1 = self.view_specific_decoder1(view_specific_feature1)\n",
        "        view_specific_output2 = self.view_specific_decoder2(view_specific_feature2)\n",
        "        view_specific_output3 = self.view_specific_decoder3(view_specific_feature3)\n",
        "\n",
        "        T1_output = self.decoder1(received_feature_T1)\n",
        "        T2_output = self.decoder2(received_feature_T2)\n",
        "\n",
        "        return F.log_softmax(T2_output, dim=1), F.log_softmax(T1_output, dim=1), \\\n",
        "               F.log_softmax(view_specific_output1, dim=1), F.log_softmax(view_specific_output2, dim=1), \\\n",
        "               F.log_softmax(view_specific_output3, dim=1), KL_loss\n",
        "\n",
        "    def IB_feature_extraction(self, x):\n",
        "        view1 = x[:, 0, :, :].view(-1, 2972 * 121)\n",
        "        view2 = x[:, 1, :, :].view(-1, 2972 * 121)\n",
        "        view3 = x[:, 2, :, :].view(-1, 2972 * 121)\n",
        "\n",
        "        feature_view1 = self.view1_feature_extraction(view1)\n",
        "        feature_view2 = self.view2_feature_extraction(view2)\n",
        "        feature_view3 = self.view3_feature_extraction(view3)\n",
        "\n",
        "        mu1 =  10 * self.view1_ib_mu(feature_view1)\n",
        "        sigma1 = self.view1_ib_sigma(feature_view1)\n",
        "\n",
        "        mu2 =  10 * self.view2_ib_mu(feature_view2)\n",
        "        sigma2 = self.view2_ib_sigma(feature_view2)\n",
        "\n",
        "        mu3 =  10 * self.view3_ib_mu(feature_view3)\n",
        "        sigma3 = self.view3_ib_sigma(feature_view3)\n",
        "\n",
        "        KL_loss = self.KL_loss(mu1, sigma1) + self.KL_loss(mu2, sigma2) + self.KL_loss(mu3, sigma3)\n",
        "\n",
        "        if self.training:\n",
        "            feature1 = self.reparameterize(mu1, sigma1)\n",
        "            feature2 = self.reparameterize(mu2, sigma2)\n",
        "            feature3 = self.reparameterize(mu3, sigma3)\n",
        "        else:\n",
        "            feature1 = mu1\n",
        "            feature2 = mu2\n",
        "            feature3 = mu3\n",
        "\n",
        "        return feature1, feature2, feature3, KL_loss\n",
        "\n",
        "    def KL_loss(self, mu, sigma, sigma2=1):\n",
        "        batch_size = mu.size()[0]\n",
        "        J = mu.size()[1]\n",
        "\n",
        "        mu_diff = mu ** 2\n",
        "        var1 = sigma ** 2\n",
        "        var2 = sigma2 ** 2\n",
        "\n",
        "        var_frac = var1 / var2\n",
        "        diff_var_frac = mu_diff / var2\n",
        "\n",
        "        term1 = torch.sum(torch.log(var_frac)) / batch_size\n",
        "        term2 = torch.sum(var_frac) / batch_size\n",
        "        term3 = torch.sum(diff_var_frac) / batch_size\n",
        "\n",
        "        return -0.5 * (term1 - term2 - term3 + J)\n",
        "\n",
        "    def IB_extractor_requires_grad(self, requires_grad=False):\n",
        "        for params in self.view1_feature_extraction.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view2_feature_extraction.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view3_feature_extraction.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view1_ib_mu.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view2_ib_mu.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view3_ib_mu.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view1_ib_sigma.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view2_ib_sigma.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "        for params in self.view3_ib_sigma.parameters():\n",
        "            params.requires_grad = requires_grad\n",
        "\n",
        "    def save_encoded_features(self, view1_1, view2_1, view3_1, view1_2, view2_2, view3_2):\n",
        "        \"\"\"Save encoded features\"\"\"\n",
        "        save_dir = 'final/dfsib'  # Save directory\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        np.save(os.path.join(save_dir, 'view1_1.npy'), view1_1.detach().cpu().numpy())\n",
        "        np.save(os.path.join(save_dir, 'view2_1.npy'), view2_1.detach().cpu().numpy())\n",
        "        np.save(os.path.join(save_dir, 'view3_1.npy'), view3_1.detach().cpu().numpy())\n",
        "\n",
        "        np.save(os.path.join(save_dir, 'view1_2.npy'), view1_2.detach().cpu().numpy())\n",
        "        np.save(os.path.join(save_dir, 'view2_2.npy'), view2_2.detach().cpu().numpy())\n",
        "        np.save(os.path.join(save_dir, 'view3_2.npy'), view3_2.detach().cpu().numpy())\n",
        "\n",
        "# The rest of the code remains unchanged\n",
        "\n",
        "def load_data(data_dir, test_size=0.2):\n",
        "    import os\n",
        "    # Load saved data\n",
        "    data_file = os.path.join(data_dir, 'data.npy')\n",
        "    label_file = os.path.join(data_dir, 'label.npy')\n",
        "    data = np.load(data_file)\n",
        "    labels = np.load(label_file)\n",
        "    data = data.transpose((0, 3, 1, 2))\n",
        "    labels -= 1\n",
        "    # Split the data into training and testing sets\n",
        "    data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Convert labels to integer type\n",
        "    labels_train = labels_train.astype(int)\n",
        "    labels_test = labels_test.astype(int)\n",
        "\n",
        "    return data_train, data_test, labels_train, labels_test\n",
        "\n",
        "def train_VIB(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, KL_loss = model(data, args)\n",
        "        loss = F.nll_loss(view_specific_output1, target) + F.nll_loss(view_specific_output2, target) + F.nll_loss(view_specific_output3, target) + 1e-4 * KL_loss  # VIB loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = T2_output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "def train_dfsib_model(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.IB_extractor_requires_grad(requires_grad=False)\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, _ = model(data, args)\n",
        "        loss = F.nll_loss(T2_output, target) + F.nll_loss(T1_output, target) + args['beta'] * (\n",
        "                    F.nll_loss(view_specific_output1, target) + F.nll_loss(view_specific_output2, target) + F.nll_loss(view_specific_output3, target))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = T2_output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def fine_tune(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, KL_loss = model(data, args)\n",
        "        loss = F.nll_loss(T2_output, target) + F.nll_loss(T1_output, target) + args['beta'] * (\n",
        "                    F.nll_loss(view_specific_output1, target) + F.nll_loss(view_specific_output2, target) + F.nll_loss(view_specific_output3, target)) + 1e-4 * KL_loss  # Fine-tuning loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = T2_output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def test_dfsib_model(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    correct_internal = 0\n",
        "    labels_test_true = []\n",
        "    labels_test_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, KL_loss = model(data, args)\n",
        "            test_loss += F.nll_loss(T2_output, target, reduction='sum').item()\n",
        "            pred = T2_output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            pred_internal = T1_output.argmax(dim=1, keepdim=True)\n",
        "            correct_internal += pred_internal.eq(target.view_as(pred_internal)).sum().item()\n",
        "            labels_test_true.extend(target.cpu().numpy())\n",
        "            labels_test_pred.extend(pred.cpu().numpy().flatten())\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    internal_accuracy = 100. * correct_internal / len(test_loader.dataset)\n",
        "    return test_loss, accuracy, internal_accuracy, labels_test_true, labels_test_pred\n",
        "\n",
        "def inference(args, model, device, test_loader, threshold):\n",
        "    model.eval()\n",
        "    count_one_trans = 0\n",
        "    all_points = 0\n",
        "    all_correct_points = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, _ = model(data,args)\n",
        "            coefficient, _ = torch.max(F.softmax(T2_output, dim=1), dim=1, keepdim=True)\n",
        "            coefficient = torch.where((coefficient) > (threshold), torch.ones(1).to(device), torch.zeros(1).to(device))\n",
        "            count_one_trans += torch.norm(coefficient, p=1)\n",
        "            output_cascade = torch.mul(T2_output, coefficient) + torch.mul(T1_output, (1 - coefficient))\n",
        "            pred_cascade = output_cascade.argmax(dim=1, keepdim=False)\n",
        "            results = pred_cascade == target\n",
        "            correct_points = torch.sum(results.long())\n",
        "            all_correct_points += correct_points\n",
        "            all_points += results.size()[0]\n",
        "        acc = all_correct_points.float() / all_points\n",
        "        acc = acc.cpu().data.numpy()\n",
        "        retransmission_ratio = 1 - (count_one_trans.float() / all_points).item()\n",
        "        communication_cost = 3 * (args['dim1'] * args['bit'] + args['dim2'] * args['bit'] * retransmission_ratio)\n",
        "        return acc, communication_cost\n",
        "\n",
        "\n",
        "def save_and_plot(history, model_dir, phase):\n",
        "    # Save training history\n",
        "    with open(os.path.join(model_dir, f'{phase}_history.pkl'), 'wb') as f:\n",
        "        pickle.dump(history, f)\n",
        "\n",
        "    # Plot training and validation accuracy curves\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{phase} Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(model_dir, f'{phase}_accuracy.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot training and validation loss curves\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{phase} Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(model_dir, f'{phase}_loss.png'))\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    data_train, data_test, labels_train, labels_test = load_data('DFS/big-multi-data')\n",
        "\n",
        "    num_classes = len(np.unique(labels_train))\n",
        "\n",
        "    train_dataset = TensorDataset(torch.Tensor(data_train), torch.LongTensor(labels_train))\n",
        "    test_dataset = TensorDataset(torch.Tensor(data_test), torch.LongTensor(labels_test))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    model = MultiViewDFSIB(input_dim=121, time_dim=2972, hidden_dim=128, output_dim=num_classes, args=args).to(device)\n",
        "\n",
        "    best_internal_acc = 0\n",
        "    best_model = []\n",
        "    model_dir = 'final/dfsib'\n",
        "\n",
        "    # Initialize history records\n",
        "    pretrain_history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': []}\n",
        "    dvib_history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': []}\n",
        "    fine_tune_history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': []}\n",
        "\n",
        "    # Pretrain the feature extractor\n",
        "    optimizer1 = optim.SGD(model.parameters(), lr=args['lr'])\n",
        "    scheduler1 = StepLR(optimizer1, step_size=10, gamma=args['gamma'])\n",
        "    for epoch in range(0, args['epochs']):  # Pretrain the feature extractor(s)\n",
        "        train_loss, train_accuracy = train_VIB(args, model, device, train_loader, optimizer1, epoch)\n",
        "        val_loss, val_accuracy, val_internal_accuracy, _, _ = test_dfsib_model(args, model, device, test_loader)\n",
        "\n",
        "        # Record history\n",
        "        pretrain_history['train_loss'].append(train_loss.item())\n",
        "        pretrain_history['val_loss'].append(val_loss)\n",
        "        pretrain_history['train_accuracy'].append(train_accuracy)\n",
        "        pretrain_history['val_accuracy'].append(val_internal_accuracy)\n",
        "\n",
        "        print('VIB training ... epoch:', epoch, \"loss\", train_loss.item())\n",
        "        scheduler1.step()\n",
        "\n",
        "    save_and_plot(pretrain_history, model_dir, 'pretrain')\n",
        "\n",
        "    # Train the DFSIB model\n",
        "    optimizer2 = optim.SGD(model.parameters(), lr=args['lr'])\n",
        "    scheduler2 = StepLR(optimizer2, step_size=10, gamma=args['gamma'])\n",
        "\n",
        "    for epoch in range(0, args['epochs']):  # Train the DFSIB\n",
        "        train_loss, train_accuracy = train_dfsib_model(args, model, device, train_loader, optimizer2, epoch)\n",
        "        val_loss, val_accuracy, val_internal_accuracy, _, _ = test_dfsib_model(args, model, device, test_loader)\n",
        "\n",
        "        # Record history\n",
        "        dvib_history['train_loss'].append(train_loss.item())\n",
        "        dvib_history['val_loss'].append(val_loss)\n",
        "        dvib_history['train_accuracy'].append(train_accuracy)\n",
        "        dvib_history['val_accuracy'].append(val_internal_accuracy)\n",
        "\n",
        "        print('DFSIB-SR training ... epoch:', epoch, \"loss\", train_loss.item())\n",
        "        scheduler2.step()\n",
        "        if val_internal_accuracy > best_internal_acc:\n",
        "            best_internal_acc = val_internal_accuracy\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    save_and_plot(dvib_history, model_dir, 'dvib')\n",
        "\n",
        "    # Fine-tune the model\n",
        "    optimizer3 = optim.SGD(model.parameters(), lr=args['lr'])\n",
        "    scheduler3 = StepLR(optimizer3, step_size=10, gamma=args['gamma'])\n",
        "\n",
        "    for epoch in range(0, args['epochs']):\n",
        "        train_loss, train_accuracy = fine_tune(args, model, device, train_loader, optimizer3, epoch)\n",
        "        val_loss, val_accuracy, val_internal_accuracy, _, _ = test_dfsib_model(args, model, device, test_loader)\n",
        "\n",
        "        # Record history\n",
        "        fine_tune_history['train_loss'].append(train_loss.item())\n",
        "        fine_tune_history['val_loss'].append(val_loss)\n",
        "        fine_tune_history['train_accuracy'].append(train_accuracy)\n",
        "        fine_tune_history['val_accuracy'].append(val_internal_accuracy)\n",
        "\n",
        "        print(f'Fine-tuning ... epoch: {epoch}')\n",
        "        print(f\"  Training Loss: {train_loss.item():.6f}\")\n",
        "        print(f\"  Training Accuracy: {train_accuracy:.2f}%\")\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"  Validation Accuracy: {val_internal_accuracy:.2f}%\")\n",
        "\n",
        "        scheduler3.step()\n",
        "        if val_internal_accuracy > best_internal_acc:\n",
        "            best_internal_acc = val_internal_accuracy\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    save_and_plot(fine_tune_history, model_dir, 'fine_tune')\n",
        "\n",
        "    # Save predicted labels and true labels\n",
        "    labels_test_true = []\n",
        "    labels_test_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            T2_output, T1_output, view_specific_output1, view_specific_output2, view_specific_output3, KL_loss = model(data, args)\n",
        "            labels_test_true.extend(target.cpu().numpy())\n",
        "            labels_test_pred.extend(T2_output.argmax(dim=1, keepdim=True).cpu().numpy().flatten())\n",
        "\n",
        "    np.save(os.path.join(model_dir, 'multi_view_fine_tune_labels_test_true.npy'), np.array(labels_test_true))\n",
        "    np.save(os.path.join(model_dir, 'multi_view_fine_tune_labels_test_pred.npy'), np.array(labels_test_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(labels_test_true, labels_test_pred)\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm = np.around(cm, decimals=2)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "    plt.title('Multi View Fine Tune Model Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.savefig(os.path.join(model_dir, 'multi_view_fine_tune_confusion_matrix.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Inference\n",
        "    model.load_state_dict(best_model)\n",
        "    threshold_list = [0.5, 0.6, 0.7, 0.8, 0.9, 0.925, 0.95, 0.96, 0.97, 0.98, 0.985, 0.99, 0.995, 1]\n",
        "    print(\"\\nInference: \\n\")\n",
        "    for threshold in threshold_list:\n",
        "        accuracy, cost = inference(args, model, device, test_loader, threshold)\n",
        "        print(f\"Threshold {threshold:.3f}: Accuracy: {accuracy * 100:.2f}%, Communication Cost: {cost:.2f} bits\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='MultiView DFSIB')\n",
        "    parser.add_argument('--dim1', type=int, default=3, help='dim 1')\n",
        "    parser.add_argument('--dim2', type=int, default=3, help='dim 2')\n",
        "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--test_batch_size', type=int, default=1000, metavar='N',\n",
        "                        help='input batch size for testing (default: 1000)')\n",
        "    parser.add_argument('--epochs', type=int, default=30)\n",
        "    parser.add_argument('--gamma', type=float, default=0.1)\n",
        "    parser.add_argument('--lr', type=float, default=0.1)\n",
        "    parser.add_argument('--bit', type=int, default=1)\n",
        "    parser.add_argument('--beta', type=float, default=1e-5)\n",
        "    parser.add_argument('--seed', type=int, default=1)\n",
        "\n",
        "    args = parser.parse_args([])\n",
        "    args = vars(args)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZFWtoEOzkTf",
        "outputId": "92d6b96c-4951-4049-809a-632323be8e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIB training ... epoch: 0 loss 5.33236837387085\n",
            "VIB training ... epoch: 1 loss 4.632900238037109\n",
            "VIB training ... epoch: 2 loss 4.724167346954346\n",
            "VIB training ... epoch: 3 loss 3.983767509460449\n",
            "VIB training ... epoch: 4 loss 3.866112232208252\n",
            "VIB training ... epoch: 5 loss 3.744169235229492\n",
            "VIB training ... epoch: 6 loss 3.329101324081421\n",
            "VIB training ... epoch: 7 loss 3.2515830993652344\n",
            "VIB training ... epoch: 8 loss 4.191378116607666\n",
            "VIB training ... epoch: 9 loss 3.7879018783569336\n",
            "VIB training ... epoch: 10 loss 4.0629143714904785\n",
            "VIB training ... epoch: 11 loss 3.0574896335601807\n",
            "VIB training ... epoch: 12 loss 3.687920570373535\n",
            "VIB training ... epoch: 13 loss 3.1522374153137207\n",
            "VIB training ... epoch: 14 loss 3.8249363899230957\n",
            "VIB training ... epoch: 15 loss 2.9671266078948975\n",
            "VIB training ... epoch: 16 loss 3.3833699226379395\n",
            "VIB training ... epoch: 17 loss 3.466383934020996\n",
            "VIB training ... epoch: 18 loss 3.409350872039795\n",
            "VIB training ... epoch: 19 loss 3.107583522796631\n",
            "VIB training ... epoch: 20 loss 2.9004201889038086\n",
            "VIB training ... epoch: 21 loss 2.809288263320923\n",
            "VIB training ... epoch: 22 loss 3.6531622409820557\n",
            "VIB training ... epoch: 23 loss 3.941483736038208\n",
            "VIB training ... epoch: 24 loss 3.5173869132995605\n",
            "VIB training ... epoch: 25 loss 3.2389895915985107\n",
            "VIB training ... epoch: 26 loss 3.3389670848846436\n",
            "VIB training ... epoch: 27 loss 2.3991668224334717\n",
            "VIB training ... epoch: 28 loss 3.0400891304016113\n",
            "VIB training ... epoch: 29 loss 2.32551646232605\n",
            "VDDIB-SR training ... epoch: 0 loss 2.8318674564361572\n",
            "VDDIB-SR training ... epoch: 1 loss 2.383673906326294\n",
            "VDDIB-SR training ... epoch: 2 loss 1.5446751117706299\n",
            "VDDIB-SR training ... epoch: 3 loss 1.8732973337173462\n",
            "VDDIB-SR training ... epoch: 4 loss 1.7245312929153442\n",
            "VDDIB-SR training ... epoch: 5 loss 1.2819732427597046\n",
            "VDDIB-SR training ... epoch: 6 loss 0.9444900155067444\n",
            "VDDIB-SR training ... epoch: 7 loss 1.0651886463165283\n",
            "VDDIB-SR training ... epoch: 8 loss 1.6162527799606323\n",
            "VDDIB-SR training ... epoch: 9 loss 1.0300054550170898\n",
            "VDDIB-SR training ... epoch: 10 loss 1.7131917476654053\n",
            "VDDIB-SR training ... epoch: 11 loss 1.1786755323410034\n",
            "VDDIB-SR training ... epoch: 12 loss 1.5894758701324463\n",
            "VDDIB-SR training ... epoch: 13 loss 0.6328878402709961\n",
            "VDDIB-SR training ... epoch: 14 loss 1.6819640398025513\n",
            "VDDIB-SR training ... epoch: 15 loss 1.5612139701843262\n",
            "VDDIB-SR training ... epoch: 16 loss 0.980531632900238\n",
            "VDDIB-SR training ... epoch: 17 loss 1.291308045387268\n",
            "VDDIB-SR training ... epoch: 18 loss 2.455897092819214\n",
            "VDDIB-SR training ... epoch: 19 loss 0.895227313041687\n",
            "VDDIB-SR training ... epoch: 20 loss 1.3145498037338257\n",
            "VDDIB-SR training ... epoch: 21 loss 1.5247000455856323\n",
            "VDDIB-SR training ... epoch: 22 loss 1.413619041442871\n",
            "VDDIB-SR training ... epoch: 23 loss 0.9468035101890564\n",
            "VDDIB-SR training ... epoch: 24 loss 0.8439978361129761\n",
            "VDDIB-SR training ... epoch: 25 loss 1.7192749977111816\n",
            "VDDIB-SR training ... epoch: 26 loss 2.051703453063965\n",
            "VDDIB-SR training ... epoch: 27 loss 0.7653894424438477\n",
            "VDDIB-SR training ... epoch: 28 loss 2.0334157943725586\n",
            "VDDIB-SR training ... epoch: 29 loss 1.2811229228973389\n",
            "Fine-tuning ... epoch: 0\n",
            "  Training Loss: 1.314469\n",
            "  Training Accuracy: 69.54%\n",
            "  Validation Loss: 1.0675\n",
            "  Validation Accuracy: 56.67%\n",
            "Fine-tuning ... epoch: 1\n",
            "  Training Loss: 2.323551\n",
            "  Training Accuracy: 70.09%\n",
            "  Validation Loss: 1.0428\n",
            "  Validation Accuracy: 59.33%\n",
            "Fine-tuning ... epoch: 2\n",
            "  Training Loss: 1.643389\n",
            "  Training Accuracy: 70.37%\n",
            "  Validation Loss: 1.0808\n",
            "  Validation Accuracy: 55.78%\n",
            "Fine-tuning ... epoch: 3\n",
            "  Training Loss: 1.137556\n",
            "  Training Accuracy: 70.26%\n",
            "  Validation Loss: 1.0401\n",
            "  Validation Accuracy: 57.33%\n",
            "Fine-tuning ... epoch: 4\n",
            "  Training Loss: 1.071240\n",
            "  Training Accuracy: 69.54%\n",
            "  Validation Loss: 1.0367\n",
            "  Validation Accuracy: 56.67%\n",
            "Fine-tuning ... epoch: 5\n",
            "  Training Loss: 1.572356\n",
            "  Training Accuracy: 70.26%\n",
            "  Validation Loss: 1.0163\n",
            "  Validation Accuracy: 59.33%\n",
            "Fine-tuning ... epoch: 6\n",
            "  Training Loss: 1.363261\n",
            "  Training Accuracy: 70.71%\n",
            "  Validation Loss: 1.0248\n",
            "  Validation Accuracy: 59.33%\n",
            "Fine-tuning ... epoch: 7\n",
            "  Training Loss: 1.840758\n",
            "  Training Accuracy: 70.48%\n",
            "  Validation Loss: 1.0547\n",
            "  Validation Accuracy: 58.67%\n",
            "Fine-tuning ... epoch: 8\n",
            "  Training Loss: 1.394304\n",
            "  Training Accuracy: 70.76%\n",
            "  Validation Loss: 1.0278\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 9\n",
            "  Training Loss: 1.527055\n",
            "  Training Accuracy: 71.54%\n",
            "  Validation Loss: 1.0455\n",
            "  Validation Accuracy: 56.00%\n",
            "Fine-tuning ... epoch: 10\n",
            "  Training Loss: 1.275506\n",
            "  Training Accuracy: 71.26%\n",
            "  Validation Loss: 1.0317\n",
            "  Validation Accuracy: 57.56%\n",
            "Fine-tuning ... epoch: 11\n",
            "  Training Loss: 0.808474\n",
            "  Training Accuracy: 71.48%\n",
            "  Validation Loss: 1.0332\n",
            "  Validation Accuracy: 58.00%\n",
            "Fine-tuning ... epoch: 12\n",
            "  Training Loss: 0.782061\n",
            "  Training Accuracy: 70.93%\n",
            "  Validation Loss: 1.0334\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 13\n",
            "  Training Loss: 1.779493\n",
            "  Training Accuracy: 71.15%\n",
            "  Validation Loss: 1.0333\n",
            "  Validation Accuracy: 57.33%\n",
            "Fine-tuning ... epoch: 14\n",
            "  Training Loss: 1.012813\n",
            "  Training Accuracy: 72.15%\n",
            "  Validation Loss: 1.0285\n",
            "  Validation Accuracy: 57.56%\n",
            "Fine-tuning ... epoch: 15\n",
            "  Training Loss: 0.901044\n",
            "  Training Accuracy: 71.26%\n",
            "  Validation Loss: 1.0225\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 16\n",
            "  Training Loss: 0.784258\n",
            "  Training Accuracy: 71.26%\n",
            "  Validation Loss: 1.0238\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 17\n",
            "  Training Loss: 1.554208\n",
            "  Training Accuracy: 72.21%\n",
            "  Validation Loss: 1.0296\n",
            "  Validation Accuracy: 57.11%\n",
            "Fine-tuning ... epoch: 18\n",
            "  Training Loss: 1.752970\n",
            "  Training Accuracy: 71.32%\n",
            "  Validation Loss: 1.0352\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 19\n",
            "  Training Loss: 1.152656\n",
            "  Training Accuracy: 71.26%\n",
            "  Validation Loss: 1.0252\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 20\n",
            "  Training Loss: 1.035534\n",
            "  Training Accuracy: 71.43%\n",
            "  Validation Loss: 1.0258\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 21\n",
            "  Training Loss: 2.428949\n",
            "  Training Accuracy: 70.98%\n",
            "  Validation Loss: 1.0260\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 22\n",
            "  Training Loss: 0.746810\n",
            "  Training Accuracy: 71.15%\n",
            "  Validation Loss: 1.0261\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 23\n",
            "  Training Loss: 2.004677\n",
            "  Training Accuracy: 70.82%\n",
            "  Validation Loss: 1.0271\n",
            "  Validation Accuracy: 58.22%\n",
            "Fine-tuning ... epoch: 24\n",
            "  Training Loss: 1.259969\n",
            "  Training Accuracy: 72.10%\n",
            "  Validation Loss: 1.0271\n",
            "  Validation Accuracy: 58.00%\n",
            "Fine-tuning ... epoch: 25\n",
            "  Training Loss: 1.269291\n",
            "  Training Accuracy: 71.48%\n",
            "  Validation Loss: 1.0271\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 26\n",
            "  Training Loss: 1.377168\n",
            "  Training Accuracy: 72.82%\n",
            "  Validation Loss: 1.0273\n",
            "  Validation Accuracy: 58.00%\n",
            "Fine-tuning ... epoch: 27\n",
            "  Training Loss: 1.749254\n",
            "  Training Accuracy: 72.26%\n",
            "  Validation Loss: 1.0274\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 28\n",
            "  Training Loss: 1.502176\n",
            "  Training Accuracy: 71.37%\n",
            "  Validation Loss: 1.0266\n",
            "  Validation Accuracy: 57.78%\n",
            "Fine-tuning ... epoch: 29\n",
            "  Training Loss: 1.041197\n",
            "  Training Accuracy: 72.15%\n",
            "  Validation Loss: 1.0266\n",
            "  Validation Accuracy: 58.00%\n",
            "\n",
            "Inference: \n",
            "\n",
            "Threshold 0.500: Accuracy: 59.56%, Communication Cost: 12.12 bits\n",
            "Threshold 0.600: Accuracy: 59.11%, Communication Cost: 13.28 bits\n",
            "Threshold 0.700: Accuracy: 59.11%, Communication Cost: 14.06 bits\n",
            "Threshold 0.800: Accuracy: 59.11%, Communication Cost: 15.02 bits\n",
            "Threshold 0.900: Accuracy: 59.33%, Communication Cost: 16.32 bits\n",
            "Threshold 0.925: Accuracy: 59.33%, Communication Cost: 16.52 bits\n",
            "Threshold 0.950: Accuracy: 59.33%, Communication Cost: 16.90 bits\n",
            "Threshold 0.960: Accuracy: 59.33%, Communication Cost: 16.96 bits\n",
            "Threshold 0.970: Accuracy: 59.33%, Communication Cost: 16.98 bits\n",
            "Threshold 0.980: Accuracy: 59.33%, Communication Cost: 16.98 bits\n",
            "Threshold 0.985: Accuracy: 59.33%, Communication Cost: 16.98 bits\n",
            "Threshold 0.990: Accuracy: 59.33%, Communication Cost: 18.00 bits\n",
            "Threshold 0.995: Accuracy: 59.33%, Communication Cost: 18.00 bits\n",
            "Threshold 1.000: Accuracy: 59.33%, Communication Cost: 18.00 bits\n"
          ]
        }
      ]
    }
  ]
}